{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e74359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebe8542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194434</th>\n",
       "      <td>A1YMNTFLNDYQ1F</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>eyeused2loveher</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Works great just like my original one. I reall...</td>\n",
       "      <td>5</td>\n",
       "      <td>This works just perfect!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194435</th>\n",
       "      <td>A15TX8B2L8B20S</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Jon Davidson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great product. Great packaging. High quality a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great replacement cable. Apple certified</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194436</th>\n",
       "      <td>A3JI7QRZO1QG8X</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Joyce M. Davidson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great cable, just as good as the mor...</td>\n",
       "      <td>5</td>\n",
       "      <td>Real quality</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194437</th>\n",
       "      <td>A1NHB2VC68YQNM</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Nurse Farrugia</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I really like it becasue it works well with my...</td>\n",
       "      <td>5</td>\n",
       "      <td>I really like it becasue it works well with my...</td>\n",
       "      <td>1405814400</td>\n",
       "      <td>07 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194438</th>\n",
       "      <td>A1AG6U022WHXBF</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Trisha Crocker</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>product as described, I have wasted a lot of m...</td>\n",
       "      <td>5</td>\n",
       "      <td>I have wasted a lot of money on cords</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194439 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin       reviewerName helpful  \\\n",
       "0       A30TL5EWN6DFXT  120401325X          christina  [0, 0]   \n",
       "1        ASY55RVNIL0UD  120401325X           emily l.  [0, 0]   \n",
       "2       A2TMXE2AFO7ONB  120401325X              Erica  [0, 0]   \n",
       "3        AWJ0WZQYMYFQ4  120401325X                 JM  [4, 4]   \n",
       "4        ATX7CZYFXI1KW  120401325X   patrice m rogoza  [2, 3]   \n",
       "...                ...         ...                ...     ...   \n",
       "194434  A1YMNTFLNDYQ1F  B00LORXVUE    eyeused2loveher  [0, 0]   \n",
       "194435  A15TX8B2L8B20S  B00LORXVUE       Jon Davidson  [0, 0]   \n",
       "194436  A3JI7QRZO1QG8X  B00LORXVUE  Joyce M. Davidson  [0, 0]   \n",
       "194437  A1NHB2VC68YQNM  B00LORXVUE     Nurse Farrugia  [0, 0]   \n",
       "194438  A1AG6U022WHXBF  B00LORXVUE     Trisha Crocker  [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "0       They look good and stick good! I just don't li...        4   \n",
       "1       These stickers work like the review says they ...        5   \n",
       "2       These are awesome and make my phone look so st...        5   \n",
       "3       Item arrived in great time and was in perfect ...        4   \n",
       "4       awesome! stays on, and looks great. can be use...        5   \n",
       "...                                                   ...      ...   \n",
       "194434  Works great just like my original one. I reall...        5   \n",
       "194435  Great product. Great packaging. High quality a...        5   \n",
       "194436  This is a great cable, just as good as the mor...        5   \n",
       "194437  I really like it becasue it works well with my...        5   \n",
       "194438  product as described, I have wasted a lot of m...        5   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "0                                              Looks Good      1400630400   \n",
       "1                                   Really great product.      1389657600   \n",
       "2                                          LOVE LOVE LOVE      1403740800   \n",
       "3                                                   Cute!      1382313600   \n",
       "4               leopard home button sticker for iphone 4s      1359849600   \n",
       "...                                                   ...             ...   \n",
       "194434                           This works just perfect!      1405900800   \n",
       "194435           Great replacement cable. Apple certified      1405900800   \n",
       "194436                                       Real quality      1405900800   \n",
       "194437  I really like it becasue it works well with my...      1405814400   \n",
       "194438              I have wasted a lot of money on cords      1405900800   \n",
       "\n",
       "         reviewTime  \n",
       "0       05 21, 2014  \n",
       "1       01 14, 2014  \n",
       "2       06 26, 2014  \n",
       "3       10 21, 2013  \n",
       "4        02 3, 2013  \n",
       "...             ...  \n",
       "194434  07 21, 2014  \n",
       "194435  07 21, 2014  \n",
       "194436  07 21, 2014  \n",
       "194437  07 20, 2014  \n",
       "194438  07 21, 2014  \n",
       "\n",
       "[194439 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(r\"C:\\Users\\sevan\\Desktop\\IIIT-H\\Word Similarity score\\Cell_Phones_and_Accessories_5.json\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c810ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d2f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [they, look, good, and, stick, good!, just, do...\n",
      "1         [these, stickers, work, like, the, review, say...\n",
      "2         [these, are, awesome, and, make, my, phone, lo...\n",
      "3         [item, arrived, in, great, time, and, was, in,...\n",
      "4         [awesome!, stays, on,, and, looks, great., can...\n",
      "                                ...                        \n",
      "194434    [works, great, just, like, my, original, one.,...\n",
      "194435    [great, product., great, packaging., high, qua...\n",
      "194436    [this, is, great, cable,, just, as, good, as, ...\n",
      "194437    [really, like, it, becasue, it, works, well, w...\n",
      "194438    [product, as, described,, have, wasted, lot, o...\n",
      "Name: processed_reviews, Length: 194439, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def simple_preprocess(text, min_len=2, max_len=15):\n",
    "    # Tokenize by splitting on non word characters and converting to lowercase\n",
    "    words = text.lower().split()\n",
    "    # Filtering words based on length\n",
    "    processed_words = [word for word in words if len(word) >= min_len and len(word) <= max_len]\n",
    "    return processed_words\n",
    "\n",
    "\n",
    "df['processed_reviews'] = df['reviewText'].apply(simple_preprocess)\n",
    "\n",
    "print(df['processed_reviews'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89afe506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [they, look, good, and, stick, good!, just, do...\n",
       "1         [these, stickers, work, like, the, review, say...\n",
       "2         [these, are, awesome, and, make, my, phone, lo...\n",
       "3         [item, arrived, in, great, time, and, was, in,...\n",
       "4         [awesome!, stays, on,, and, looks, great., can...\n",
       "                                ...                        \n",
       "194434    [works, great, just, like, my, original, one.,...\n",
       "194435    [great, product., great, packaging., high, qua...\n",
       "194436    [this, is, great, cable,, just, as, good, as, ...\n",
       "194437    [really, like, it, becasue, it, works, well, w...\n",
       "194438    [product, as, described,, have, wasted, lot, o...\n",
       "Name: processed_reviews, Length: 194439, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedReviews=df.processed_reviews\n",
    "processedReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22dc675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good!',\n",
       " 'just',\n",
       " \"don't\",\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating.',\n",
       " 'just',\n",
       " \"won't\",\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.processed_reviews.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c5397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3694bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(processedReviews, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c82d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:51:50,011 : INFO : collecting all words and their counts\n",
      "2024-05-02 09:51:50,012 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-02 09:51:50,167 : INFO : PROGRESS: at sentence #10000, processed 1014330 words, keeping 54851 word types\n",
      "2024-05-02 09:51:50,312 : INFO : PROGRESS: at sentence #20000, processed 1922618 words, keeping 82115 word types\n",
      "2024-05-02 09:51:50,441 : INFO : PROGRESS: at sentence #30000, processed 2745097 words, keeping 102925 word types\n",
      "2024-05-02 09:51:50,567 : INFO : PROGRESS: at sentence #40000, processed 3571574 words, keeping 121803 word types\n",
      "2024-05-02 09:51:50,689 : INFO : PROGRESS: at sentence #50000, processed 4331219 words, keeping 138169 word types\n",
      "2024-05-02 09:51:50,820 : INFO : PROGRESS: at sentence #60000, processed 5167631 words, keeping 154827 word types\n",
      "2024-05-02 09:51:50,942 : INFO : PROGRESS: at sentence #70000, processed 5957394 words, keeping 170514 word types\n",
      "2024-05-02 09:51:51,058 : INFO : PROGRESS: at sentence #80000, processed 6670758 words, keeping 182996 word types\n",
      "2024-05-02 09:51:51,176 : INFO : PROGRESS: at sentence #90000, processed 7432626 words, keeping 196371 word types\n",
      "2024-05-02 09:51:51,276 : INFO : PROGRESS: at sentence #100000, processed 8068810 words, keeping 205894 word types\n",
      "2024-05-02 09:51:51,369 : INFO : PROGRESS: at sentence #110000, processed 8672871 words, keeping 214606 word types\n",
      "2024-05-02 09:51:51,492 : INFO : PROGRESS: at sentence #120000, processed 9470304 words, keeping 227077 word types\n",
      "2024-05-02 09:51:51,608 : INFO : PROGRESS: at sentence #130000, processed 10200590 words, keeping 238369 word types\n",
      "2024-05-02 09:51:51,752 : INFO : PROGRESS: at sentence #140000, processed 11083160 words, keeping 252286 word types\n",
      "2024-05-02 09:51:51,890 : INFO : PROGRESS: at sentence #150000, processed 11957858 words, keeping 265173 word types\n",
      "2024-05-02 09:51:52,027 : INFO : PROGRESS: at sentence #160000, processed 12811777 words, keeping 277104 word types\n",
      "2024-05-02 09:51:52,174 : INFO : PROGRESS: at sentence #170000, processed 13747088 words, keeping 291566 word types\n",
      "2024-05-02 09:51:52,353 : INFO : PROGRESS: at sentence #180000, processed 14874548 words, keeping 309220 word types\n",
      "2024-05-02 09:51:52,550 : INFO : PROGRESS: at sentence #190000, processed 16115838 words, keeping 327952 word types\n",
      "2024-05-02 09:51:52,643 : INFO : collected 336698 word types from a corpus of 16678840 raw words and 194439 sentences\n",
      "2024-05-02 09:51:52,644 : INFO : Creating a fresh vocabulary\n",
      "2024-05-02 09:51:53,590 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 336698 unique words (100.00% of original 336698, drops 0)', 'datetime': '2024-05-02T09:51:53.590816', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-02 09:51:53,591 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 16678840 word corpus (100.00% of original 16678840, drops 0)', 'datetime': '2024-05-02T09:51:53.591821', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-02 09:51:55,001 : INFO : deleting the raw counts dictionary of 336698 items\n",
      "2024-05-02 09:51:55,007 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2024-05-02 09:51:55,008 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 12695795.349478379 word corpus (76.1%% of prior 16678840)', 'datetime': '2024-05-02T09:51:55.008368', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-02 09:51:57,302 : INFO : estimated required memory for 336698 words and 100 dimensions: 437707400 bytes\n",
      "2024-05-02 09:51:57,303 : INFO : resetting layer weights\n",
      "2024-05-02 09:51:57,422 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-02T09:51:57.421104', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'build_vocab'}\n",
      "2024-05-02 09:51:57,422 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 336698 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-05-02T09:51:57.422106', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2024-05-02 09:51:58,462 : INFO : EPOCH 0 - PROGRESS: at 1.72% examples, 266544 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:51:59,488 : INFO : EPOCH 0 - PROGRESS: at 3.58% examples, 269176 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:00,495 : INFO : EPOCH 0 - PROGRESS: at 5.47% examples, 274131 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:01,501 : INFO : EPOCH 0 - PROGRESS: at 7.35% examples, 276753 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:02,524 : INFO : EPOCH 0 - PROGRESS: at 9.64% examples, 278991 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:03,536 : INFO : EPOCH 0 - PROGRESS: at 12.38% examples, 280631 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:04,574 : INFO : EPOCH 0 - PROGRESS: at 14.60% examples, 279965 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:05,614 : INFO : EPOCH 0 - PROGRESS: at 16.65% examples, 276241 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:06,664 : INFO : EPOCH 0 - PROGRESS: at 19.11% examples, 273995 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:07,697 : INFO : EPOCH 0 - PROGRESS: at 21.41% examples, 275619 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:08,731 : INFO : EPOCH 0 - PROGRESS: at 23.95% examples, 276947 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:09,778 : INFO : EPOCH 0 - PROGRESS: at 26.82% examples, 277878 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:10,834 : INFO : EPOCH 0 - PROGRESS: at 28.89% examples, 276291 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:11,843 : INFO : EPOCH 0 - PROGRESS: at 31.14% examples, 275766 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:12,862 : INFO : EPOCH 0 - PROGRESS: at 33.62% examples, 275482 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:13,887 : INFO : EPOCH 0 - PROGRESS: at 35.89% examples, 275695 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:14,915 : INFO : EPOCH 0 - PROGRESS: at 38.74% examples, 276678 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:15,939 : INFO : EPOCH 0 - PROGRESS: at 41.47% examples, 277490 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:16,947 : INFO : EPOCH 0 - PROGRESS: at 44.31% examples, 278996 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:18,002 : INFO : EPOCH 0 - PROGRESS: at 46.83% examples, 278552 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:19,018 : INFO : EPOCH 0 - PROGRESS: at 49.79% examples, 278165 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:20,058 : INFO : EPOCH 0 - PROGRESS: at 53.02% examples, 277889 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:21,080 : INFO : EPOCH 0 - PROGRESS: at 56.46% examples, 278620 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:22,104 : INFO : EPOCH 0 - PROGRESS: at 59.06% examples, 279296 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:23,145 : INFO : EPOCH 0 - PROGRESS: at 61.53% examples, 279564 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:24,158 : INFO : EPOCH 0 - PROGRESS: at 64.14% examples, 280164 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:25,175 : INFO : EPOCH 0 - PROGRESS: at 67.06% examples, 280690 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:26,191 : INFO : EPOCH 0 - PROGRESS: at 69.41% examples, 280966 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:27,194 : INFO : EPOCH 0 - PROGRESS: at 71.57% examples, 281237 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:28,202 : INFO : EPOCH 0 - PROGRESS: at 73.74% examples, 281262 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:29,234 : INFO : EPOCH 0 - PROGRESS: at 76.33% examples, 281784 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:52:30,235 : INFO : EPOCH 0 - PROGRESS: at 78.45% examples, 282153 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:31,259 : INFO : EPOCH 0 - PROGRESS: at 80.63% examples, 282028 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:32,270 : INFO : EPOCH 0 - PROGRESS: at 83.08% examples, 282419 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:33,305 : INFO : EPOCH 0 - PROGRESS: at 85.20% examples, 282658 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:34,319 : INFO : EPOCH 0 - PROGRESS: at 87.32% examples, 283036 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:35,353 : INFO : EPOCH 0 - PROGRESS: at 88.91% examples, 282927 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:36,359 : INFO : EPOCH 0 - PROGRESS: at 90.61% examples, 282887 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:37,374 : INFO : EPOCH 0 - PROGRESS: at 92.47% examples, 283049 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:38,380 : INFO : EPOCH 0 - PROGRESS: at 94.22% examples, 283082 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:39,452 : INFO : EPOCH 0 - PROGRESS: at 95.83% examples, 282982 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:40,466 : INFO : EPOCH 0 - PROGRESS: at 97.25% examples, 283161 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:41,467 : INFO : EPOCH 0 - PROGRESS: at 98.84% examples, 283197 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:42,248 : INFO : EPOCH 0: training on 16678840 raw words (12694463 effective words) took 44.8s, 283336 effective words/s\n",
      "2024-05-02 09:52:43,302 : INFO : EPOCH 1 - PROGRESS: at 1.81% examples, 265905 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:44,309 : INFO : EPOCH 1 - PROGRESS: at 3.71% examples, 278441 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:45,310 : INFO : EPOCH 1 - PROGRESS: at 5.72% examples, 283476 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:46,327 : INFO : EPOCH 1 - PROGRESS: at 7.57% examples, 282951 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:47,337 : INFO : EPOCH 1 - PROGRESS: at 9.81% examples, 283136 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:48,378 : INFO : EPOCH 1 - PROGRESS: at 12.50% examples, 283826 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:49,421 : INFO : EPOCH 1 - PROGRESS: at 14.87% examples, 284681 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:50,425 : INFO : EPOCH 1 - PROGRESS: at 17.31% examples, 286198 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:51,465 : INFO : EPOCH 1 - PROGRESS: at 19.78% examples, 286441 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:52,473 : INFO : EPOCH 1 - PROGRESS: at 22.48% examples, 287540 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:53,512 : INFO : EPOCH 1 - PROGRESS: at 24.94% examples, 287670 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:54,535 : INFO : EPOCH 1 - PROGRESS: at 27.65% examples, 288334 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:55,540 : INFO : EPOCH 1 - PROGRESS: at 30.03% examples, 288643 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:56,549 : INFO : EPOCH 1 - PROGRESS: at 32.72% examples, 288672 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:52:57,567 : INFO : EPOCH 1 - PROGRESS: at 34.80% examples, 289104 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:58,608 : INFO : EPOCH 1 - PROGRESS: at 38.02% examples, 289991 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:52:59,625 : INFO : EPOCH 1 - PROGRESS: at 40.78% examples, 290236 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:00,679 : INFO : EPOCH 1 - PROGRESS: at 43.42% examples, 289929 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:01,716 : INFO : EPOCH 1 - PROGRESS: at 46.09% examples, 290002 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:02,733 : INFO : EPOCH 1 - PROGRESS: at 49.23% examples, 290494 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:03,820 : INFO : EPOCH 1 - PROGRESS: at 52.89% examples, 290737 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:04,831 : INFO : EPOCH 1 - PROGRESS: at 56.01% examples, 289721 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:05,890 : INFO : EPOCH 1 - PROGRESS: at 58.68% examples, 289520 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:06,934 : INFO : EPOCH 1 - PROGRESS: at 61.12% examples, 289362 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:07,936 : INFO : EPOCH 1 - PROGRESS: at 63.74% examples, 289675 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:08,948 : INFO : EPOCH 1 - PROGRESS: at 66.77% examples, 290204 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:09,950 : INFO : EPOCH 1 - PROGRESS: at 68.94% examples, 290040 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:10,960 : INFO : EPOCH 1 - PROGRESS: at 71.32% examples, 290170 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:11,973 : INFO : EPOCH 1 - PROGRESS: at 73.58% examples, 290363 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:12,975 : INFO : EPOCH 1 - PROGRESS: at 76.01% examples, 290381 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:13,980 : INFO : EPOCH 1 - PROGRESS: at 78.09% examples, 290253 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:14,988 : INFO : EPOCH 1 - PROGRESS: at 80.12% examples, 289095 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:16,000 : INFO : EPOCH 1 - PROGRESS: at 82.09% examples, 287950 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:17,043 : INFO : EPOCH 1 - PROGRESS: at 84.16% examples, 287286 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:18,051 : INFO : EPOCH 1 - PROGRESS: at 86.31% examples, 287394 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:19,105 : INFO : EPOCH 1 - PROGRESS: at 88.17% examples, 287168 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:20,109 : INFO : EPOCH 1 - PROGRESS: at 89.73% examples, 287127 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:21,164 : INFO : EPOCH 1 - PROGRESS: at 91.48% examples, 286621 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:22,190 : INFO : EPOCH 1 - PROGRESS: at 93.39% examples, 286805 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:23,214 : INFO : EPOCH 1 - PROGRESS: at 94.98% examples, 286902 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:24,215 : INFO : EPOCH 1 - PROGRESS: at 96.69% examples, 287103 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:25,226 : INFO : EPOCH 1 - PROGRESS: at 98.13% examples, 286844 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:26,263 : INFO : EPOCH 1 - PROGRESS: at 99.60% examples, 286828 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:26,499 : INFO : EPOCH 1: training on 16678840 raw words (12696011 effective words) took 44.2s, 286946 effective words/s\n",
      "2024-05-02 09:53:27,519 : INFO : EPOCH 2 - PROGRESS: at 1.81% examples, 274146 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:28,541 : INFO : EPOCH 2 - PROGRESS: at 3.71% examples, 280735 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:29,589 : INFO : EPOCH 2 - PROGRESS: at 5.76% examples, 283221 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:30,630 : INFO : EPOCH 2 - PROGRESS: at 7.76% examples, 284765 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:31,667 : INFO : EPOCH 2 - PROGRESS: at 10.34% examples, 286104 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:32,668 : INFO : EPOCH 2 - PROGRESS: at 12.69% examples, 286938 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:33,685 : INFO : EPOCH 2 - PROGRESS: at 14.94% examples, 286272 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:34,693 : INFO : EPOCH 2 - PROGRESS: at 17.37% examples, 286502 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:35,758 : INFO : EPOCH 2 - PROGRESS: at 19.89% examples, 286785 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:53:36,787 : INFO : EPOCH 2 - PROGRESS: at 22.59% examples, 287225 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:37,796 : INFO : EPOCH 2 - PROGRESS: at 25.17% examples, 288152 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:38,844 : INFO : EPOCH 2 - PROGRESS: at 27.70% examples, 287577 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:39,844 : INFO : EPOCH 2 - PROGRESS: at 30.10% examples, 288645 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:40,865 : INFO : EPOCH 2 - PROGRESS: at 33.05% examples, 289469 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:41,866 : INFO : EPOCH 2 - PROGRESS: at 34.87% examples, 288698 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:42,886 : INFO : EPOCH 2 - PROGRESS: at 37.98% examples, 289045 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:53:43,904 : INFO : EPOCH 2 - PROGRESS: at 40.45% examples, 288077 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:44,911 : INFO : EPOCH 2 - PROGRESS: at 43.00% examples, 287737 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:45,920 : INFO : EPOCH 2 - PROGRESS: at 45.63% examples, 287960 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:46,944 : INFO : EPOCH 2 - PROGRESS: at 48.77% examples, 288829 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:47,986 : INFO : EPOCH 2 - PROGRESS: at 52.28% examples, 289390 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:49,041 : INFO : EPOCH 2 - PROGRESS: at 55.83% examples, 289515 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:50,058 : INFO : EPOCH 2 - PROGRESS: at 58.63% examples, 289835 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:51,090 : INFO : EPOCH 2 - PROGRESS: at 61.07% examples, 290118 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:52,118 : INFO : EPOCH 2 - PROGRESS: at 63.67% examples, 290127 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:53,121 : INFO : EPOCH 2 - PROGRESS: at 66.60% examples, 290441 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:54,121 : INFO : EPOCH 2 - PROGRESS: at 68.88% examples, 290580 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:55,159 : INFO : EPOCH 2 - PROGRESS: at 71.24% examples, 290418 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:56,193 : INFO : EPOCH 2 - PROGRESS: at 73.53% examples, 290386 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:57,198 : INFO : EPOCH 2 - PROGRESS: at 76.01% examples, 290619 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:58,211 : INFO : EPOCH 2 - PROGRESS: at 78.19% examples, 290881 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:53:59,216 : INFO : EPOCH 2 - PROGRESS: at 80.40% examples, 290636 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:00,241 : INFO : EPOCH 2 - PROGRESS: at 82.91% examples, 290661 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:01,253 : INFO : EPOCH 2 - PROGRESS: at 84.94% examples, 290652 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:02,269 : INFO : EPOCH 2 - PROGRESS: at 86.97% examples, 290380 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:03,327 : INFO : EPOCH 2 - PROGRESS: at 88.63% examples, 290066 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:04,352 : INFO : EPOCH 2 - PROGRESS: at 90.38% examples, 290117 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:05,419 : INFO : EPOCH 2 - PROGRESS: at 92.34% examples, 289871 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:06,452 : INFO : EPOCH 2 - PROGRESS: at 94.19% examples, 289916 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:07,463 : INFO : EPOCH 2 - PROGRESS: at 95.77% examples, 290046 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:08,474 : INFO : EPOCH 2 - PROGRESS: at 97.18% examples, 289723 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:09,520 : INFO : EPOCH 2 - PROGRESS: at 98.73% examples, 289486 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:10,361 : INFO : EPOCH 2: training on 16678840 raw words (12695889 effective words) took 43.9s, 289470 effective words/s\n",
      "2024-05-02 09:54:11,395 : INFO : EPOCH 3 - PROGRESS: at 1.81% examples, 270381 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:12,431 : INFO : EPOCH 3 - PROGRESS: at 3.73% examples, 280896 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:13,441 : INFO : EPOCH 3 - PROGRESS: at 5.76% examples, 284280 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:14,448 : INFO : EPOCH 3 - PROGRESS: at 7.60% examples, 284284 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:15,482 : INFO : EPOCH 3 - PROGRESS: at 10.11% examples, 285833 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:16,499 : INFO : EPOCH 3 - PROGRESS: at 12.65% examples, 287191 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:17,516 : INFO : EPOCH 3 - PROGRESS: at 14.90% examples, 286444 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:18,531 : INFO : EPOCH 3 - PROGRESS: at 17.37% examples, 287390 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:19,572 : INFO : EPOCH 3 - PROGRESS: at 19.89% examples, 288269 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:20,583 : INFO : EPOCH 3 - PROGRESS: at 22.59% examples, 289103 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:21,644 : INFO : EPOCH 3 - PROGRESS: at 25.36% examples, 289829 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:22,673 : INFO : EPOCH 3 - PROGRESS: at 27.89% examples, 290709 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:23,711 : INFO : EPOCH 3 - PROGRESS: at 30.32% examples, 290790 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:24,716 : INFO : EPOCH 3 - PROGRESS: at 33.24% examples, 291263 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:25,717 : INFO : EPOCH 3 - PROGRESS: at 35.13% examples, 290882 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:26,757 : INFO : EPOCH 3 - PROGRESS: at 38.28% examples, 291176 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:27,764 : INFO : EPOCH 3 - PROGRESS: at 41.02% examples, 291539 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:28,764 : INFO : EPOCH 3 - PROGRESS: at 43.62% examples, 291648 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:29,765 : INFO : EPOCH 3 - PROGRESS: at 46.23% examples, 291755 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:30,770 : INFO : EPOCH 3 - PROGRESS: at 49.23% examples, 291574 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:31,782 : INFO : EPOCH 3 - PROGRESS: at 52.70% examples, 292100 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:32,798 : INFO : EPOCH 3 - PROGRESS: at 56.19% examples, 292265 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:33,842 : INFO : EPOCH 3 - PROGRESS: at 58.77% examples, 292133 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:34,860 : INFO : EPOCH 3 - PROGRESS: at 61.25% examples, 292172 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:35,862 : INFO : EPOCH 3 - PROGRESS: at 63.74% examples, 291806 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:36,871 : INFO : EPOCH 3 - PROGRESS: at 66.60% examples, 291705 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:37,901 : INFO : EPOCH 3 - PROGRESS: at 68.94% examples, 291743 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:38,927 : INFO : EPOCH 3 - PROGRESS: at 71.32% examples, 291667 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:39,934 : INFO : EPOCH 3 - PROGRESS: at 73.53% examples, 291603 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:40,951 : INFO : EPOCH 3 - PROGRESS: at 76.01% examples, 291679 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:41,981 : INFO : EPOCH 3 - PROGRESS: at 78.09% examples, 291260 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:42,988 : INFO : EPOCH 3 - PROGRESS: at 80.27% examples, 290986 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:43,999 : INFO : EPOCH 3 - PROGRESS: at 82.61% examples, 290700 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:45,061 : INFO : EPOCH 3 - PROGRESS: at 84.85% examples, 290451 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:54:46,088 : INFO : EPOCH 3 - PROGRESS: at 86.93% examples, 290531 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:47,092 : INFO : EPOCH 3 - PROGRESS: at 88.54% examples, 290440 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:48,162 : INFO : EPOCH 3 - PROGRESS: at 90.30% examples, 290122 words/s, in_qsize 8, out_qsize 1\n",
      "2024-05-02 09:54:49,176 : INFO : EPOCH 3 - PROGRESS: at 92.22% examples, 290281 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:50,196 : INFO : EPOCH 3 - PROGRESS: at 94.08% examples, 290232 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:51,212 : INFO : EPOCH 3 - PROGRESS: at 95.53% examples, 290130 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:52,221 : INFO : EPOCH 3 - PROGRESS: at 97.11% examples, 290194 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:53,237 : INFO : EPOCH 3 - PROGRESS: at 98.70% examples, 289995 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:54,134 : INFO : EPOCH 3: training on 16678840 raw words (12696650 effective words) took 43.8s, 290091 effective words/s\n",
      "2024-05-02 09:54:55,170 : INFO : EPOCH 4 - PROGRESS: at 1.81% examples, 270242 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:56,222 : INFO : EPOCH 4 - PROGRESS: at 3.73% examples, 278186 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:57,228 : INFO : EPOCH 4 - PROGRESS: at 5.76% examples, 282718 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:54:58,232 : INFO : EPOCH 4 - PROGRESS: at 7.60% examples, 283276 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:54:59,251 : INFO : EPOCH 4 - PROGRESS: at 10.01% examples, 284406 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:00,287 : INFO : EPOCH 4 - PROGRESS: at 12.54% examples, 283949 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:55:01,348 : INFO : EPOCH 4 - PROGRESS: at 14.93% examples, 283889 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:02,359 : INFO : EPOCH 4 - PROGRESS: at 17.46% examples, 286236 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:03,372 : INFO : EPOCH 4 - PROGRESS: at 19.89% examples, 287260 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:04,415 : INFO : EPOCH 4 - PROGRESS: at 22.59% examples, 287236 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:05,432 : INFO : EPOCH 4 - PROGRESS: at 25.13% examples, 287981 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:06,466 : INFO : EPOCH 4 - PROGRESS: at 27.43% examples, 285301 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:55:07,490 : INFO : EPOCH 4 - PROGRESS: at 29.70% examples, 283770 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:08,498 : INFO : EPOCH 4 - PROGRESS: at 32.23% examples, 283588 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:55:09,515 : INFO : EPOCH 4 - PROGRESS: at 34.27% examples, 283893 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:10,523 : INFO : EPOCH 4 - PROGRESS: at 37.31% examples, 284772 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:11,535 : INFO : EPOCH 4 - PROGRESS: at 40.05% examples, 285388 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:12,544 : INFO : EPOCH 4 - PROGRESS: at 42.59% examples, 285584 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:13,579 : INFO : EPOCH 4 - PROGRESS: at 45.38% examples, 285967 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:55:14,588 : INFO : EPOCH 4 - PROGRESS: at 48.29% examples, 286465 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:55:15,593 : INFO : EPOCH 4 - PROGRESS: at 51.59% examples, 286912 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:16,602 : INFO : EPOCH 4 - PROGRESS: at 55.17% examples, 287719 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:17,627 : INFO : EPOCH 4 - PROGRESS: at 58.14% examples, 287981 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:18,631 : INFO : EPOCH 4 - PROGRESS: at 60.44% examples, 288097 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:19,687 : INFO : EPOCH 4 - PROGRESS: at 62.83% examples, 287870 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:20,690 : INFO : EPOCH 4 - PROGRESS: at 65.90% examples, 288270 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:55:21,718 : INFO : EPOCH 4 - PROGRESS: at 68.33% examples, 288208 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:22,726 : INFO : EPOCH 4 - PROGRESS: at 70.55% examples, 288193 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:23,741 : INFO : EPOCH 4 - PROGRESS: at 72.93% examples, 288422 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:24,790 : INFO : EPOCH 4 - PROGRESS: at 75.38% examples, 288308 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:25,844 : INFO : EPOCH 4 - PROGRESS: at 77.49% examples, 288214 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:26,875 : INFO : EPOCH 4 - PROGRESS: at 79.93% examples, 288300 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:27,910 : INFO : EPOCH 4 - PROGRESS: at 82.26% examples, 288322 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:28,913 : INFO : EPOCH 4 - PROGRESS: at 84.47% examples, 288415 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:29,964 : INFO : EPOCH 4 - PROGRESS: at 86.55% examples, 288162 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:30,997 : INFO : EPOCH 4 - PROGRESS: at 88.39% examples, 288277 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:31,999 : INFO : EPOCH 4 - PROGRESS: at 90.06% examples, 288392 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:33,058 : INFO : EPOCH 4 - PROGRESS: at 91.86% examples, 288035 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 09:55:34,107 : INFO : EPOCH 4 - PROGRESS: at 93.78% examples, 288006 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:35,138 : INFO : EPOCH 4 - PROGRESS: at 95.33% examples, 288029 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:36,163 : INFO : EPOCH 4 - PROGRESS: at 96.91% examples, 287844 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:37,224 : INFO : EPOCH 4 - PROGRESS: at 98.52% examples, 287768 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 09:55:38,226 : INFO : EPOCH 4 - PROGRESS: at 100.00% examples, 287899 words/s, in_qsize 0, out_qsize 1\n",
      "2024-05-02 09:55:38,227 : INFO : EPOCH 4: training on 16678840 raw words (12692810 effective words) took 44.1s, 287893 effective words/s\n",
      "2024-05-02 09:55:38,227 : INFO : Word2Vec lifecycle event {'msg': 'training on 83394200 raw words (63475823 effective words) took 220.8s, 287475 effective words/s', 'datetime': '2024-05-02T09:55:38.227273', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2024-05-02 09:55:38,228 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=336698, vector_size=100, alpha=0.025>', 'datetime': '2024-05-02T09:55:38.228274', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
      "2024-05-02 09:55:38,239 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec_cellphone_dataset.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-05-02T09:55:38.239280', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'saving'}\n",
      "2024-05-02 09:55:38,240 : INFO : storing np array 'vectors' to word2vec_cellphone_dataset.model.wv.vectors.npy\n",
      "2024-05-02 09:55:38,349 : INFO : storing np array 'syn1neg' to word2vec_cellphone_dataset.model.syn1neg.npy\n",
      "2024-05-02 09:55:38,454 : INFO : not storing attribute cum_table\n",
      "2024-05-02 09:55:38,605 : INFO : saved word2vec_cellphone_dataset.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "\n",
    "# Enable logging to monitor training\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(processedReviews, vector_size=100, window=10, min_count=1, workers=4, sg=1, epochs=5)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "print(\"Model training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab997eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:55:42,771 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 09:55:42,858 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 09:55:42,859 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 09:55:42,905 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 09:55:42,946 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 09:55:45,116 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T09:55:45.116856', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'sad': [-0.31991735  0.61761045  0.05208514  0.03930529  0.29666072 -0.34780216\n",
      "  0.64811367  0.360159   -0.04323401 -0.16191998  0.10738119 -0.42201245\n",
      "  0.14222378 -0.36545    -0.19581582  0.04333167  0.14310923 -0.43724793\n",
      " -0.1715229  -0.7481259  -0.10643549 -0.00739809  0.392186    0.16554365\n",
      " -0.7947068  -0.33961955  0.07029798 -0.48285046 -0.04220633  0.11941839\n",
      " -0.22194245 -0.28600937  0.7793108  -0.10329352 -0.15668984  0.4225642\n",
      "  0.1358447  -0.04787092 -0.34575665 -0.1715253  -0.06524143  0.21105024\n",
      "  0.11322075  0.02084793  0.5289066  -0.02938805  0.16560328  0.3418028\n",
      " -0.10204348  0.43890998  0.20989196 -0.16598785  0.07044207 -0.01317306\n",
      "  0.22261144 -0.0865225  -0.35020986 -0.22326283  0.051339    0.04440468\n",
      " -0.32823834 -0.1492731   0.13849978 -0.34001863 -0.25325492  0.09727008\n",
      " -0.16894524  0.46475586 -0.07118986  0.6332999  -0.10561807  0.0323921\n",
      "  0.4583577   0.24577658  0.24692005 -0.04001218  0.0646824   0.35070547\n",
      "  0.13454439  0.17035016 -0.03825903 -0.5629347  -0.12956625  0.28299314\n",
      " -0.03417236 -0.22858997  0.42182732 -0.24777237  0.02662845  0.13463955\n",
      "  0.2898623   0.09719691 -0.26907566 -0.11398148  0.66277736 -0.39677808\n",
      " -0.10330795 -0.19926105  0.0823225  -0.24092613]\n",
      "Similar words to 'sad': [('upset', 0.8251710534095764), ('bummed', 0.7938408851623535), ('dissapointed', 0.7917989492416382), ('sad,', 0.7872381210327148), ('bad...', 0.7754298448562622), ('sad.', 0.7695761919021606), ('fluke.', 0.7682157754898071), ('mad', 0.7644446492195129), ('upset.', 0.7634435892105103), ('dissapointing.', 0.7628764510154724)]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "word='sad'\n",
    "# Get the vector for a word\n",
    "vector = model.wv[word]  # replace 'example' with any word\n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.wv.most_similar(word, topn=10)  # replace 'example'\n",
    "\n",
    "print(f\"Vector for '{word}':\", vector)\n",
    "print(f\"Similar words to '{word}':\", similar_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbac925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:55:52,119 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 09:55:52,205 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 09:55:52,206 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 09:55:52,247 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 09:55:52,283 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 09:55:54,428 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T09:55:54.428705', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'smart' and 'intelligent': 0.58506006\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "# Function to calculate similarity between two words\n",
    "def get_similarity(word1, word2):\n",
    "    # Check if both words are in the vocabulary\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        # Calculate similarity\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        return similarity\n",
    "    else:\n",
    "        return \"One or both words not in the vocabulary!\"\n",
    "\n",
    "# Example usage\n",
    "word1 = 'smart'  # Replace 'example1' with your word\n",
    "word2 = 'intelligent' # Replace 'example2' with your word\n",
    "\n",
    "similarity_score = get_similarity(word1, word2)\n",
    "print(f\"Similarity between '{word1}' and '{word2}':\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fb351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84770f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabba4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d200300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09162f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:56:09,409 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 09:56:09,494 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 09:56:09,496 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 09:56:09,537 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 09:56:09,573 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 09:56:11,717 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T09:56:11.716732', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'smart': [-0.1345035   0.19312446  0.0200062  -0.05131509  0.5278145  -0.47450656\n",
      "  0.0491282   0.48079404 -0.18368115 -0.17316508 -0.35943085  0.03628269\n",
      "  0.0931293   0.06177653  0.18806987 -0.09625044  0.3622171  -0.02355837\n",
      " -0.02087122 -0.41670674  0.12857343  0.31652924 -0.24244401 -0.26172167\n",
      " -0.20918217 -0.00126359 -0.26407057  0.11674844 -0.04963433 -0.23518932\n",
      " -0.15773743  0.26435295  0.6165295  -0.06159683 -0.35286054  0.13262312\n",
      "  0.02289065  0.01153676  0.17438613 -0.578304   -0.17525765 -0.1107737\n",
      " -0.34127605  0.12419467  0.39951104 -0.01677754 -0.36083767  0.34032807\n",
      " -0.05093221  0.03409414  0.34800807 -0.36213315  0.41018987  0.0295787\n",
      "  0.35560244  0.3631178   0.2286692  -0.06922931 -0.31899548  0.1938544\n",
      " -0.13606884  0.16972871  0.18029702 -0.33444828 -0.33546954  0.44216642\n",
      " -0.13025191 -0.00717954 -0.41942954  0.35803232  0.24684173  0.6542497\n",
      "  0.15561001  0.54107076  0.4833591   0.19281738  0.05434475  0.28005758\n",
      " -0.1528987   0.2889768  -0.3111693  -0.2745086  -0.06422804  0.39935324\n",
      " -0.23011711  0.04332728  0.3030797   0.2561936   0.58387375  0.00899052\n",
      "  0.15501349  0.39265501  0.10905281  0.37564912  0.36833403  0.24685499\n",
      "  0.08127082 -0.21978962  0.4303199  -0.45559716]\n",
      "Similar words to 'smart': [('cell', 0.8155460953712463), ('smartphone', 0.8113691210746765), ('windows-based', 0.7861706614494324), (\"friends'\", 0.7839409112930298), ('non-smart', 0.7792791128158569), ('mobile', 0.7791284322738647), ('zune,', 0.7790181040763855), ('smart-phones', 0.7761397957801819), ('kindles.', 0.7754867076873779), ('pda,', 0.7747774124145508)]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "word='smart'\n",
    "# Get the vector for a word\n",
    "vector = model.wv[word]  # replace 'example' with any word\n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.wv.most_similar(word, topn=10)  # replace 'example'\n",
    "\n",
    "print(f\"Vector for '{word}':\", vector)\n",
    "print(f\"Similar words to '{word}':\", similar_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db21bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:56:20,617 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 09:56:20,702 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 09:56:20,704 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 09:56:20,747 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 09:56:20,785 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 09:56:22,940 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T09:56:22.940280', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'smart' and 'dumb': 0.6052871\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "# Function to calculate similarity between two words\n",
    "def get_similarity(word1, word2):\n",
    "    # Check if both words are in the vocabulary\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        # Calculate similarity\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        return similarity\n",
    "    else:\n",
    "        return \"One or both words not in the vocabulary!\"\n",
    "\n",
    "# Example usage\n",
    "word1 = 'smart'  # Replace 'example1' with your word\n",
    "word2 = 'dumb' # Replace 'example2' with your word\n",
    "\n",
    "similarity_score = get_similarity(word1, word2)\n",
    "print(f\"Similarity between '{word1}' and '{word2}':\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fa22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479941db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac537044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7994f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305940b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:56:25,383 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 09:56:25,467 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 09:56:25,468 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 09:56:25,509 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 09:56:25,546 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 09:56:27,686 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T09:56:27.686879', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.221\n",
      "   word1        word2  SimLex999  predicted_similarity\n",
      "0    old          new       1.58              0.669180\n",
      "1  smart  intelligent       9.20              0.585060\n",
      "2   hard    difficult       8.77              0.820678\n",
      "3  happy     cheerful       9.55              0.544823\n",
      "4   hard         easy       0.95              0.672322\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the Word2Vec model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "def get_similarity(model, word1, word2):\n",
    "    # Check if both words are in the vocabulary\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        # Calculate similarity\n",
    "        return model.wv.similarity(word1, word2)\n",
    "    else:\n",
    "        return None  # Return None if one or both words are not in the vocabulary\n",
    "\n",
    "# Load SimLex-999 data\n",
    "simlex_path =r\"C:\\Users\\sevan\\Desktop\\IIIT-H\\SimLex-999\\SimLex-999\\SimLex-999.txt\"  # Update the path to where you've saved SimLex-999\n",
    "simlex_data = pd.read_csv(simlex_path, sep='\\t')\n",
    "\n",
    "# Calculate similarities using the model\n",
    "simlex_data['predicted_similarity'] = simlex_data.apply(lambda row: get_similarity(model, row['word1'], row['word2']), axis=1)\n",
    "\n",
    "# Drop rows where similarity could not be calculated because the word was not in the vocabulary\n",
    "simlex_data.dropna(subset=['predicted_similarity'], inplace=True)\n",
    "\n",
    "# Calculate the Spearman correlation between human ratings and model's predictions\n",
    "correlation, _ = spearmanr(simlex_data['SimLex999'], simlex_data['predicted_similarity'])\n",
    "print(f\"Spearman correlation: {correlation:.3f}\")\n",
    "\n",
    "print(simlex_data[['word1', 'word2', 'SimLex999', 'predicted_similarity']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8de8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80d215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978149c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68de989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449e4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95568cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6878db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f8d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
