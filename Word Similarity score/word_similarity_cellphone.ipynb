{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e74359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebe8542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194434</th>\n",
       "      <td>A1YMNTFLNDYQ1F</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>eyeused2loveher</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Works great just like my original one. I reall...</td>\n",
       "      <td>5</td>\n",
       "      <td>This works just perfect!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194435</th>\n",
       "      <td>A15TX8B2L8B20S</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Jon Davidson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Great product. Great packaging. High quality a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great replacement cable. Apple certified</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194436</th>\n",
       "      <td>A3JI7QRZO1QG8X</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Joyce M. Davidson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great cable, just as good as the mor...</td>\n",
       "      <td>5</td>\n",
       "      <td>Real quality</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194437</th>\n",
       "      <td>A1NHB2VC68YQNM</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Nurse Farrugia</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I really like it becasue it works well with my...</td>\n",
       "      <td>5</td>\n",
       "      <td>I really like it becasue it works well with my...</td>\n",
       "      <td>1405814400</td>\n",
       "      <td>07 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194438</th>\n",
       "      <td>A1AG6U022WHXBF</td>\n",
       "      <td>B00LORXVUE</td>\n",
       "      <td>Trisha Crocker</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>product as described, I have wasted a lot of m...</td>\n",
       "      <td>5</td>\n",
       "      <td>I have wasted a lot of money on cords</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194439 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin       reviewerName helpful  \\\n",
       "0       A30TL5EWN6DFXT  120401325X          christina  [0, 0]   \n",
       "1        ASY55RVNIL0UD  120401325X           emily l.  [0, 0]   \n",
       "2       A2TMXE2AFO7ONB  120401325X              Erica  [0, 0]   \n",
       "3        AWJ0WZQYMYFQ4  120401325X                 JM  [4, 4]   \n",
       "4        ATX7CZYFXI1KW  120401325X   patrice m rogoza  [2, 3]   \n",
       "...                ...         ...                ...     ...   \n",
       "194434  A1YMNTFLNDYQ1F  B00LORXVUE    eyeused2loveher  [0, 0]   \n",
       "194435  A15TX8B2L8B20S  B00LORXVUE       Jon Davidson  [0, 0]   \n",
       "194436  A3JI7QRZO1QG8X  B00LORXVUE  Joyce M. Davidson  [0, 0]   \n",
       "194437  A1NHB2VC68YQNM  B00LORXVUE     Nurse Farrugia  [0, 0]   \n",
       "194438  A1AG6U022WHXBF  B00LORXVUE     Trisha Crocker  [0, 0]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "0       They look good and stick good! I just don't li...        4   \n",
       "1       These stickers work like the review says they ...        5   \n",
       "2       These are awesome and make my phone look so st...        5   \n",
       "3       Item arrived in great time and was in perfect ...        4   \n",
       "4       awesome! stays on, and looks great. can be use...        5   \n",
       "...                                                   ...      ...   \n",
       "194434  Works great just like my original one. I reall...        5   \n",
       "194435  Great product. Great packaging. High quality a...        5   \n",
       "194436  This is a great cable, just as good as the mor...        5   \n",
       "194437  I really like it becasue it works well with my...        5   \n",
       "194438  product as described, I have wasted a lot of m...        5   \n",
       "\n",
       "                                                  summary  unixReviewTime  \\\n",
       "0                                              Looks Good      1400630400   \n",
       "1                                   Really great product.      1389657600   \n",
       "2                                          LOVE LOVE LOVE      1403740800   \n",
       "3                                                   Cute!      1382313600   \n",
       "4               leopard home button sticker for iphone 4s      1359849600   \n",
       "...                                                   ...             ...   \n",
       "194434                           This works just perfect!      1405900800   \n",
       "194435           Great replacement cable. Apple certified      1405900800   \n",
       "194436                                       Real quality      1405900800   \n",
       "194437  I really like it becasue it works well with my...      1405814400   \n",
       "194438              I have wasted a lot of money on cords      1405900800   \n",
       "\n",
       "         reviewTime  \n",
       "0       05 21, 2014  \n",
       "1       01 14, 2014  \n",
       "2       06 26, 2014  \n",
       "3       10 21, 2013  \n",
       "4        02 3, 2013  \n",
       "...             ...  \n",
       "194434  07 21, 2014  \n",
       "194435  07 21, 2014  \n",
       "194436  07 21, 2014  \n",
       "194437  07 20, 2014  \n",
       "194438  07 21, 2014  \n",
       "\n",
       "[194439 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(r\"C:\\Users\\sevan\\Desktop\\IIIT-H\\Word Similarity score\\Cell_Phones_and_Accessories_5.json\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c810ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d2f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [they, look, good, and, stick, good!, just, do...\n",
      "1         [these, stickers, work, like, the, review, say...\n",
      "2         [these, are, awesome, and, make, my, phone, lo...\n",
      "3         [item, arrived, in, great, time, and, was, in,...\n",
      "4         [awesome!, stays, on,, and, looks, great., can...\n",
      "                                ...                        \n",
      "194434    [works, great, just, like, my, original, one.,...\n",
      "194435    [great, product., great, packaging., high, qua...\n",
      "194436    [this, is, great, cable,, just, as, good, as, ...\n",
      "194437    [really, like, it, becasue, it, works, well, w...\n",
      "194438    [product, as, described,, have, wasted, lot, o...\n",
      "Name: processed_reviews, Length: 194439, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def simple_preprocess(text, min_len=2, max_len=15):\n",
    "    # Tokenize by splitting on non word characters and converting to lowercase\n",
    "    words = text.lower().split()\n",
    "    # Filtering words based on length\n",
    "    processed_words = [word for word in words if len(word) >= min_len and len(word) <= max_len]\n",
    "    return processed_words\n",
    "\n",
    "\n",
    "df['processed_reviews'] = df['reviewText'].apply(simple_preprocess)\n",
    "\n",
    "print(df['processed_reviews'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89afe506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [they, look, good, and, stick, good!, just, do...\n",
       "1         [these, stickers, work, like, the, review, say...\n",
       "2         [these, are, awesome, and, make, my, phone, lo...\n",
       "3         [item, arrived, in, great, time, and, was, in,...\n",
       "4         [awesome!, stays, on,, and, looks, great., can...\n",
       "                                ...                        \n",
       "194434    [works, great, just, like, my, original, one.,...\n",
       "194435    [great, product., great, packaging., high, qua...\n",
       "194436    [this, is, great, cable,, just, as, good, as, ...\n",
       "194437    [really, like, it, becasue, it, works, well, w...\n",
       "194438    [product, as, described,, have, wasted, lot, o...\n",
       "Name: processed_reviews, Length: 194439, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedReviews=df.processed_reviews\n",
    "processedReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22dc675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good!',\n",
       " 'just',\n",
       " \"don't\",\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating.',\n",
       " 'just',\n",
       " \"won't\",\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.processed_reviews.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c5397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(window=10,min_count=2,workers=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3694bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(processedReviews, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c82d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:59:59,753 : INFO : collecting all words and their counts\n",
      "2024-05-02 09:59:59,754 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-05-02 09:59:59,906 : INFO : PROGRESS: at sentence #10000, processed 1014330 words, keeping 54851 word types\n",
      "2024-05-02 10:00:00,064 : INFO : PROGRESS: at sentence #20000, processed 1922618 words, keeping 82115 word types\n",
      "2024-05-02 10:00:00,195 : INFO : PROGRESS: at sentence #30000, processed 2745097 words, keeping 102925 word types\n",
      "2024-05-02 10:00:00,320 : INFO : PROGRESS: at sentence #40000, processed 3571574 words, keeping 121803 word types\n",
      "2024-05-02 10:00:00,440 : INFO : PROGRESS: at sentence #50000, processed 4331219 words, keeping 138169 word types\n",
      "2024-05-02 10:00:00,570 : INFO : PROGRESS: at sentence #60000, processed 5167631 words, keeping 154827 word types\n",
      "2024-05-02 10:00:00,689 : INFO : PROGRESS: at sentence #70000, processed 5957394 words, keeping 170514 word types\n",
      "2024-05-02 10:00:00,804 : INFO : PROGRESS: at sentence #80000, processed 6670758 words, keeping 182996 word types\n",
      "2024-05-02 10:00:00,924 : INFO : PROGRESS: at sentence #90000, processed 7432626 words, keeping 196371 word types\n",
      "2024-05-02 10:00:01,020 : INFO : PROGRESS: at sentence #100000, processed 8068810 words, keeping 205894 word types\n",
      "2024-05-02 10:00:01,114 : INFO : PROGRESS: at sentence #110000, processed 8672871 words, keeping 214606 word types\n",
      "2024-05-02 10:00:01,235 : INFO : PROGRESS: at sentence #120000, processed 9470304 words, keeping 227077 word types\n",
      "2024-05-02 10:00:01,350 : INFO : PROGRESS: at sentence #130000, processed 10200590 words, keeping 238369 word types\n",
      "2024-05-02 10:00:01,486 : INFO : PROGRESS: at sentence #140000, processed 11083160 words, keeping 252286 word types\n",
      "2024-05-02 10:00:01,625 : INFO : PROGRESS: at sentence #150000, processed 11957858 words, keeping 265173 word types\n",
      "2024-05-02 10:00:01,755 : INFO : PROGRESS: at sentence #160000, processed 12811777 words, keeping 277104 word types\n",
      "2024-05-02 10:00:01,900 : INFO : PROGRESS: at sentence #170000, processed 13747088 words, keeping 291566 word types\n",
      "2024-05-02 10:00:02,074 : INFO : PROGRESS: at sentence #180000, processed 14874548 words, keeping 309220 word types\n",
      "2024-05-02 10:00:02,291 : INFO : PROGRESS: at sentence #190000, processed 16115838 words, keeping 327952 word types\n",
      "2024-05-02 10:00:02,386 : INFO : collected 336698 word types from a corpus of 16678840 raw words and 194439 sentences\n",
      "2024-05-02 10:00:02,387 : INFO : Creating a fresh vocabulary\n",
      "2024-05-02 10:00:03,349 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 336698 unique words (100.00% of original 336698, drops 0)', 'datetime': '2024-05-02T10:00:03.349065', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-02 10:00:03,350 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 16678840 word corpus (100.00% of original 16678840, drops 0)', 'datetime': '2024-05-02T10:00:03.350061', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-02 10:00:04,803 : INFO : deleting the raw counts dictionary of 336698 items\n",
      "2024-05-02 10:00:04,809 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2024-05-02 10:00:04,810 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 12695795.349478379 word corpus (76.1%% of prior 16678840)', 'datetime': '2024-05-02T10:00:04.810573', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-02 10:00:07,110 : INFO : estimated required memory for 336698 words and 100 dimensions: 437707400 bytes\n",
      "2024-05-02 10:00:07,111 : INFO : resetting layer weights\n",
      "2024-05-02 10:00:07,226 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-05-02T10:00:07.226686', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'build_vocab'}\n",
      "2024-05-02 10:00:07,227 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 336698 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2024-05-02T10:00:07.227972', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2024-05-02 10:00:08,261 : INFO : EPOCH 0 - PROGRESS: at 1.36% examples, 211772 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:09,275 : INFO : EPOCH 0 - PROGRESS: at 3.19% examples, 237264 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:10,281 : INFO : EPOCH 0 - PROGRESS: at 4.58% examples, 229778 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:11,296 : INFO : EPOCH 0 - PROGRESS: at 6.20% examples, 231922 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:12,312 : INFO : EPOCH 0 - PROGRESS: at 7.84% examples, 233057 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:13,323 : INFO : EPOCH 0 - PROGRESS: at 9.64% examples, 232865 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:14,326 : INFO : EPOCH 0 - PROGRESS: at 12.06% examples, 235846 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:15,328 : INFO : EPOCH 0 - PROGRESS: at 14.09% examples, 240212 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:16,357 : INFO : EPOCH 0 - PROGRESS: at 16.18% examples, 240907 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:17,379 : INFO : EPOCH 0 - PROGRESS: at 18.56% examples, 243836 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:18,414 : INFO : EPOCH 0 - PROGRESS: at 20.60% examples, 244124 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:19,436 : INFO : EPOCH 0 - PROGRESS: at 22.59% examples, 242115 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:20,436 : INFO : EPOCH 0 - PROGRESS: at 24.59% examples, 241934 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:21,473 : INFO : EPOCH 0 - PROGRESS: at 27.23% examples, 244943 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:22,517 : INFO : EPOCH 0 - PROGRESS: at 29.41% examples, 246001 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:23,554 : INFO : EPOCH 0 - PROGRESS: at 31.75% examples, 246876 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:24,582 : INFO : EPOCH 0 - PROGRESS: at 33.84% examples, 247832 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:25,601 : INFO : EPOCH 0 - PROGRESS: at 36.14% examples, 247987 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:26,603 : INFO : EPOCH 0 - PROGRESS: at 38.55% examples, 248335 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:27,632 : INFO : EPOCH 0 - PROGRESS: at 41.30% examples, 250066 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:28,660 : INFO : EPOCH 0 - PROGRESS: at 43.87% examples, 251807 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:29,670 : INFO : EPOCH 0 - PROGRESS: at 46.39% examples, 252853 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:30,680 : INFO : EPOCH 0 - PROGRESS: at 49.28% examples, 254009 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:31,703 : INFO : EPOCH 0 - PROGRESS: at 52.54% examples, 254942 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:32,705 : INFO : EPOCH 0 - PROGRESS: at 55.83% examples, 256140 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:33,740 : INFO : EPOCH 0 - PROGRESS: at 58.58% examples, 256971 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:34,751 : INFO : EPOCH 0 - PROGRESS: at 60.79% examples, 258083 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:35,766 : INFO : EPOCH 0 - PROGRESS: at 63.08% examples, 258603 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:36,769 : INFO : EPOCH 0 - PROGRESS: at 65.84% examples, 258936 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:37,778 : INFO : EPOCH 0 - PROGRESS: at 67.87% examples, 258280 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:38,788 : INFO : EPOCH 0 - PROGRESS: at 69.88% examples, 257796 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:00:39,843 : INFO : EPOCH 0 - PROGRESS: at 71.84% examples, 257682 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:40,861 : INFO : EPOCH 0 - PROGRESS: at 73.81% examples, 257461 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:41,911 : INFO : EPOCH 0 - PROGRESS: at 76.07% examples, 257421 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:42,938 : INFO : EPOCH 0 - PROGRESS: at 78.09% examples, 257860 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:43,950 : INFO : EPOCH 0 - PROGRESS: at 80.30% examples, 258487 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:44,966 : INFO : EPOCH 0 - PROGRESS: at 82.61% examples, 259069 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:45,988 : INFO : EPOCH 0 - PROGRESS: at 84.79% examples, 259790 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:47,014 : INFO : EPOCH 0 - PROGRESS: at 86.71% examples, 260086 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:48,057 : INFO : EPOCH 0 - PROGRESS: at 88.43% examples, 260662 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:49,064 : INFO : EPOCH 0 - PROGRESS: at 90.09% examples, 261212 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:50,100 : INFO : EPOCH 0 - PROGRESS: at 91.83% examples, 261348 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:51,148 : INFO : EPOCH 0 - PROGRESS: at 93.60% examples, 261458 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:52,157 : INFO : EPOCH 0 - PROGRESS: at 95.08% examples, 261889 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:53,213 : INFO : EPOCH 0 - PROGRESS: at 96.69% examples, 261969 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:54,222 : INFO : EPOCH 0 - PROGRESS: at 98.09% examples, 262125 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:55,270 : INFO : EPOCH 0 - PROGRESS: at 99.54% examples, 262429 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:55,551 : INFO : EPOCH 0: training on 16678840 raw words (12694471 effective words) took 48.3s, 262716 effective words/s\n",
      "2024-05-02 10:00:56,557 : INFO : EPOCH 1 - PROGRESS: at 1.48% examples, 239822 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:57,571 : INFO : EPOCH 1 - PROGRESS: at 3.25% examples, 247091 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:00:58,592 : INFO : EPOCH 1 - PROGRESS: at 5.17% examples, 257579 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:00:59,636 : INFO : EPOCH 1 - PROGRESS: at 6.97% examples, 262138 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:00,655 : INFO : EPOCH 1 - PROGRESS: at 8.81% examples, 260018 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:01,687 : INFO : EPOCH 1 - PROGRESS: at 11.55% examples, 261788 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:02,690 : INFO : EPOCH 1 - PROGRESS: at 13.58% examples, 265980 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:03,691 : INFO : EPOCH 1 - PROGRESS: at 15.91% examples, 266456 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:04,697 : INFO : EPOCH 1 - PROGRESS: at 18.08% examples, 265641 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:05,770 : INFO : EPOCH 1 - PROGRESS: at 20.47% examples, 265702 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:06,771 : INFO : EPOCH 1 - PROGRESS: at 22.81% examples, 265917 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:07,812 : INFO : EPOCH 1 - PROGRESS: at 25.13% examples, 265455 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:08,814 : INFO : EPOCH 1 - PROGRESS: at 27.65% examples, 267063 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:09,826 : INFO : EPOCH 1 - PROGRESS: at 30.01% examples, 268206 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:10,827 : INFO : EPOCH 1 - PROGRESS: at 32.55% examples, 269244 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:11,853 : INFO : EPOCH 1 - PROGRESS: at 34.18% examples, 267016 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:12,881 : INFO : EPOCH 1 - PROGRESS: at 36.79% examples, 266367 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:13,945 : INFO : EPOCH 1 - PROGRESS: at 39.35% examples, 266065 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:14,947 : INFO : EPOCH 1 - PROGRESS: at 41.52% examples, 265044 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:15,982 : INFO : EPOCH 1 - PROGRESS: at 43.88% examples, 264168 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:17,002 : INFO : EPOCH 1 - PROGRESS: at 46.31% examples, 264230 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:18,014 : INFO : EPOCH 1 - PROGRESS: at 49.14% examples, 264560 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:19,055 : INFO : EPOCH 1 - PROGRESS: at 52.54% examples, 265526 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:20,077 : INFO : EPOCH 1 - PROGRESS: at 55.83% examples, 266110 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:21,094 : INFO : EPOCH 1 - PROGRESS: at 58.58% examples, 266753 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:22,097 : INFO : EPOCH 1 - PROGRESS: at 60.59% examples, 266761 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:23,111 : INFO : EPOCH 1 - PROGRESS: at 62.78% examples, 266709 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:24,123 : INFO : EPOCH 1 - PROGRESS: at 65.63% examples, 266968 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:25,152 : INFO : EPOCH 1 - PROGRESS: at 67.93% examples, 266854 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:26,153 : INFO : EPOCH 1 - PROGRESS: at 70.09% examples, 266905 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:27,171 : INFO : EPOCH 1 - PROGRESS: at 72.00% examples, 266552 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:28,175 : INFO : EPOCH 1 - PROGRESS: at 73.81% examples, 265465 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:29,193 : INFO : EPOCH 1 - PROGRESS: at 76.01% examples, 265213 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:30,227 : INFO : EPOCH 1 - PROGRESS: at 77.91% examples, 265163 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:31,246 : INFO : EPOCH 1 - PROGRESS: at 80.19% examples, 265560 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:32,268 : INFO : EPOCH 1 - PROGRESS: at 82.46% examples, 265918 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:33,341 : INFO : EPOCH 1 - PROGRESS: at 84.60% examples, 265905 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:34,376 : INFO : EPOCH 1 - PROGRESS: at 86.53% examples, 265796 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:35,388 : INFO : EPOCH 1 - PROGRESS: at 88.27% examples, 266059 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:36,403 : INFO : EPOCH 1 - PROGRESS: at 89.76% examples, 266086 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:37,414 : INFO : EPOCH 1 - PROGRESS: at 91.48% examples, 266435 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:38,468 : INFO : EPOCH 1 - PROGRESS: at 93.28% examples, 266561 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:39,478 : INFO : EPOCH 1 - PROGRESS: at 94.85% examples, 266869 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:40,484 : INFO : EPOCH 1 - PROGRESS: at 96.47% examples, 267128 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:41,545 : INFO : EPOCH 1 - PROGRESS: at 97.79% examples, 267044 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:42,577 : INFO : EPOCH 1 - PROGRESS: at 99.16% examples, 266893 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:43,087 : INFO : EPOCH 1: training on 16678840 raw words (12696011 effective words) took 47.5s, 267108 effective words/s\n",
      "2024-05-02 10:01:44,115 : INFO : EPOCH 2 - PROGRESS: at 1.53% examples, 242102 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:45,146 : INFO : EPOCH 2 - PROGRESS: at 3.44% examples, 253251 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:46,175 : INFO : EPOCH 2 - PROGRESS: at 5.21% examples, 256154 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:47,175 : INFO : EPOCH 2 - PROGRESS: at 7.03% examples, 263778 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:48,215 : INFO : EPOCH 2 - PROGRESS: at 9.04% examples, 264654 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:49,261 : INFO : EPOCH 2 - PROGRESS: at 11.93% examples, 268541 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:50,304 : INFO : EPOCH 2 - PROGRESS: at 14.23% examples, 270471 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:51,307 : INFO : EPOCH 2 - PROGRESS: at 16.45% examples, 272014 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:01:52,367 : INFO : EPOCH 2 - PROGRESS: at 19.14% examples, 273151 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:01:53,405 : INFO : EPOCH 2 - PROGRESS: at 21.50% examples, 274708 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:54,442 : INFO : EPOCH 2 - PROGRESS: at 23.63% examples, 272048 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:55,460 : INFO : EPOCH 2 - PROGRESS: at 25.79% examples, 267958 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:56,467 : INFO : EPOCH 2 - PROGRESS: at 27.57% examples, 264174 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:57,475 : INFO : EPOCH 2 - PROGRESS: at 29.36% examples, 260823 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:58,491 : INFO : EPOCH 2 - PROGRESS: at 31.14% examples, 257807 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:01:59,539 : INFO : EPOCH 2 - PROGRESS: at 33.41% examples, 255474 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:00,540 : INFO : EPOCH 2 - PROGRESS: at 34.72% examples, 253296 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:01,541 : INFO : EPOCH 2 - PROGRESS: at 37.08% examples, 251784 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:02,590 : INFO : EPOCH 2 - PROGRESS: at 38.99% examples, 249407 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:03,687 : INFO : EPOCH 2 - PROGRESS: at 41.28% examples, 247704 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:04,692 : INFO : EPOCH 2 - PROGRESS: at 43.25% examples, 246619 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:05,732 : INFO : EPOCH 2 - PROGRESS: at 45.30% examples, 244990 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:06,785 : INFO : EPOCH 2 - PROGRESS: at 47.30% examples, 243458 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:07,845 : INFO : EPOCH 2 - PROGRESS: at 49.89% examples, 242722 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:08,873 : INFO : EPOCH 2 - PROGRESS: at 52.54% examples, 242006 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:09,898 : INFO : EPOCH 2 - PROGRESS: at 55.17% examples, 241170 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:10,990 : INFO : EPOCH 2 - PROGRESS: at 57.51% examples, 240386 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:12,032 : INFO : EPOCH 2 - PROGRESS: at 59.46% examples, 239770 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:13,077 : INFO : EPOCH 2 - PROGRESS: at 61.31% examples, 238905 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:14,099 : INFO : EPOCH 2 - PROGRESS: at 63.08% examples, 237981 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:15,099 : INFO : EPOCH 2 - PROGRESS: at 65.46% examples, 237561 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:16,151 : INFO : EPOCH 2 - PROGRESS: at 67.31% examples, 236609 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:17,159 : INFO : EPOCH 2 - PROGRESS: at 69.05% examples, 235995 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:18,203 : INFO : EPOCH 2 - PROGRESS: at 70.72% examples, 235320 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:19,204 : INFO : EPOCH 2 - PROGRESS: at 72.47% examples, 235018 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:20,220 : INFO : EPOCH 2 - PROGRESS: at 74.23% examples, 234438 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:21,233 : INFO : EPOCH 2 - PROGRESS: at 76.07% examples, 234072 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:22,256 : INFO : EPOCH 2 - PROGRESS: at 77.56% examples, 233566 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:23,296 : INFO : EPOCH 2 - PROGRESS: at 79.46% examples, 233312 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:24,335 : INFO : EPOCH 2 - PROGRESS: at 81.08% examples, 232676 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:25,386 : INFO : EPOCH 2 - PROGRESS: at 83.03% examples, 232399 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:26,392 : INFO : EPOCH 2 - PROGRESS: at 84.58% examples, 232039 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:27,404 : INFO : EPOCH 2 - PROGRESS: at 86.21% examples, 231668 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:28,470 : INFO : EPOCH 2 - PROGRESS: at 87.67% examples, 231189 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:29,516 : INFO : EPOCH 2 - PROGRESS: at 88.76% examples, 230576 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:30,531 : INFO : EPOCH 2 - PROGRESS: at 90.09% examples, 230377 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:31,552 : INFO : EPOCH 2 - PROGRESS: at 91.41% examples, 229839 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:32,596 : INFO : EPOCH 2 - PROGRESS: at 92.79% examples, 229554 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:33,681 : INFO : EPOCH 2 - PROGRESS: at 94.22% examples, 229089 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:34,687 : INFO : EPOCH 2 - PROGRESS: at 95.26% examples, 228653 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:35,709 : INFO : EPOCH 2 - PROGRESS: at 96.58% examples, 228526 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:36,757 : INFO : EPOCH 2 - PROGRESS: at 97.59% examples, 228149 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:37,786 : INFO : EPOCH 2 - PROGRESS: at 98.84% examples, 227971 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:38,808 : INFO : EPOCH 2 - PROGRESS: at 99.89% examples, 227655 words/s, in_qsize 2, out_qsize 1\n",
      "2024-05-02 10:02:38,865 : INFO : EPOCH 2: training on 16678840 raw words (12696392 effective words) took 55.8s, 227641 effective words/s\n",
      "2024-05-02 10:02:39,922 : INFO : EPOCH 3 - PROGRESS: at 1.29% examples, 199723 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:40,934 : INFO : EPOCH 3 - PROGRESS: at 2.85% examples, 208734 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:41,935 : INFO : EPOCH 3 - PROGRESS: at 4.14% examples, 211350 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:42,944 : INFO : EPOCH 3 - PROGRESS: at 5.72% examples, 212790 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:43,989 : INFO : EPOCH 3 - PROGRESS: at 7.14% examples, 213562 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:45,015 : INFO : EPOCH 3 - PROGRESS: at 8.74% examples, 213366 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:46,025 : INFO : EPOCH 3 - PROGRESS: at 10.82% examples, 213870 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:47,086 : INFO : EPOCH 3 - PROGRESS: at 12.65% examples, 214431 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:48,102 : INFO : EPOCH 3 - PROGRESS: at 14.49% examples, 214591 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:49,117 : INFO : EPOCH 3 - PROGRESS: at 16.22% examples, 215210 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:50,140 : INFO : EPOCH 3 - PROGRESS: at 17.99% examples, 214879 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:51,155 : INFO : EPOCH 3 - PROGRESS: at 19.83% examples, 215452 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:52,175 : INFO : EPOCH 3 - PROGRESS: at 21.86% examples, 215260 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:53,177 : INFO : EPOCH 3 - PROGRESS: at 23.63% examples, 215889 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:54,183 : INFO : EPOCH 3 - PROGRESS: at 25.69% examples, 215483 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:55,183 : INFO : EPOCH 3 - PROGRESS: at 27.43% examples, 215705 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:56,213 : INFO : EPOCH 3 - PROGRESS: at 29.29% examples, 215921 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:02:57,216 : INFO : EPOCH 3 - PROGRESS: at 31.14% examples, 216439 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:58,304 : INFO : EPOCH 3 - PROGRESS: at 33.35% examples, 215878 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:02:59,319 : INFO : EPOCH 3 - PROGRESS: at 34.52% examples, 215428 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:00,369 : INFO : EPOCH 3 - PROGRESS: at 37.02% examples, 215749 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:01,423 : INFO : EPOCH 3 - PROGRESS: at 39.22% examples, 216315 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:02,429 : INFO : EPOCH 3 - PROGRESS: at 41.34% examples, 216878 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:03,458 : INFO : EPOCH 3 - PROGRESS: at 43.25% examples, 216658 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:04,472 : INFO : EPOCH 3 - PROGRESS: at 45.38% examples, 217244 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:05,496 : INFO : EPOCH 3 - PROGRESS: at 47.32% examples, 216958 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:03:06,522 : INFO : EPOCH 3 - PROGRESS: at 49.87% examples, 217302 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:03:07,598 : INFO : EPOCH 3 - PROGRESS: at 52.61% examples, 217458 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:08,644 : INFO : EPOCH 3 - PROGRESS: at 55.40% examples, 217913 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:09,655 : INFO : EPOCH 3 - PROGRESS: at 57.51% examples, 217854 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:10,680 : INFO : EPOCH 3 - PROGRESS: at 59.41% examples, 217921 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:11,717 : INFO : EPOCH 3 - PROGRESS: at 61.18% examples, 217643 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:12,785 : INFO : EPOCH 3 - PROGRESS: at 63.08% examples, 217603 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:13,795 : INFO : EPOCH 3 - PROGRESS: at 65.49% examples, 217963 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:14,819 : INFO : EPOCH 3 - PROGRESS: at 67.39% examples, 217820 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:03:15,871 : INFO : EPOCH 3 - PROGRESS: at 69.20% examples, 217711 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:16,874 : INFO : EPOCH 3 - PROGRESS: at 70.72% examples, 217432 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:17,883 : INFO : EPOCH 3 - PROGRESS: at 72.47% examples, 217565 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:03:18,917 : INFO : EPOCH 3 - PROGRESS: at 74.31% examples, 217562 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:19,925 : INFO : EPOCH 3 - PROGRESS: at 76.07% examples, 217498 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:03:20,951 : INFO : EPOCH 3 - PROGRESS: at 77.62% examples, 217588 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:21,973 : INFO : EPOCH 3 - PROGRESS: at 79.43% examples, 217479 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:22,976 : INFO : EPOCH 3 - PROGRESS: at 81.08% examples, 217602 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:24,029 : INFO : EPOCH 3 - PROGRESS: at 82.99% examples, 217502 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:25,151 : INFO : EPOCH 3 - PROGRESS: at 84.54% examples, 216944 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:26,188 : INFO : EPOCH 3 - PROGRESS: at 86.09% examples, 216650 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:27,208 : INFO : EPOCH 3 - PROGRESS: at 87.36% examples, 216114 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:28,294 : INFO : EPOCH 3 - PROGRESS: at 88.43% examples, 215358 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:03:29,295 : INFO : EPOCH 3 - PROGRESS: at 89.70% examples, 215415 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:30,314 : INFO : EPOCH 3 - PROGRESS: at 91.01% examples, 215361 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:31,340 : INFO : EPOCH 3 - PROGRESS: at 92.44% examples, 215298 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:32,392 : INFO : EPOCH 3 - PROGRESS: at 93.78% examples, 215131 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:33,451 : INFO : EPOCH 3 - PROGRESS: at 94.90% examples, 215034 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:34,452 : INFO : EPOCH 3 - PROGRESS: at 96.21% examples, 214985 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:35,457 : INFO : EPOCH 3 - PROGRESS: at 97.18% examples, 214904 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:36,466 : INFO : EPOCH 3 - PROGRESS: at 98.40% examples, 214944 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:37,512 : INFO : EPOCH 3 - PROGRESS: at 99.46% examples, 214762 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:37,983 : INFO : EPOCH 3: training on 16678840 raw words (12696555 effective words) took 59.1s, 214782 effective words/s\n",
      "2024-05-02 10:03:39,039 : INFO : EPOCH 4 - PROGRESS: at 1.29% examples, 200082 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:40,059 : INFO : EPOCH 4 - PROGRESS: at 2.85% examples, 208094 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:03:41,084 : INFO : EPOCH 4 - PROGRESS: at 4.21% examples, 211685 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:42,120 : INFO : EPOCH 4 - PROGRESS: at 5.76% examples, 211567 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:43,144 : INFO : EPOCH 4 - PROGRESS: at 7.14% examples, 211996 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:44,155 : INFO : EPOCH 4 - PROGRESS: at 8.75% examples, 213875 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:45,202 : INFO : EPOCH 4 - PROGRESS: at 10.91% examples, 213092 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:46,246 : INFO : EPOCH 4 - PROGRESS: at 12.61% examples, 212382 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:03:47,274 : INFO : EPOCH 4 - PROGRESS: at 14.49% examples, 213364 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:48,312 : INFO : EPOCH 4 - PROGRESS: at 16.18% examples, 212874 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:49,320 : INFO : EPOCH 4 - PROGRESS: at 17.99% examples, 213663 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:50,426 : INFO : EPOCH 4 - PROGRESS: at 19.91% examples, 213396 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:51,431 : INFO : EPOCH 4 - PROGRESS: at 22.10% examples, 214719 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:52,459 : INFO : EPOCH 4 - PROGRESS: at 23.74% examples, 214491 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:53,477 : INFO : EPOCH 4 - PROGRESS: at 25.94% examples, 214979 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:54,527 : INFO : EPOCH 4 - PROGRESS: at 27.73% examples, 215010 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:55,535 : INFO : EPOCH 4 - PROGRESS: at 29.65% examples, 215588 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:56,555 : INFO : EPOCH 4 - PROGRESS: at 31.45% examples, 215440 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:57,575 : INFO : EPOCH 4 - PROGRESS: at 33.47% examples, 215342 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:58,576 : INFO : EPOCH 4 - PROGRESS: at 34.80% examples, 215063 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:03:59,621 : INFO : EPOCH 4 - PROGRESS: at 37.22% examples, 215439 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:00,624 : INFO : EPOCH 4 - PROGRESS: at 39.22% examples, 215524 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:01,648 : INFO : EPOCH 4 - PROGRESS: at 41.30% examples, 215636 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:02,686 : INFO : EPOCH 4 - PROGRESS: at 43.25% examples, 215721 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:03,700 : INFO : EPOCH 4 - PROGRESS: at 45.32% examples, 215752 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:04,727 : INFO : EPOCH 4 - PROGRESS: at 47.26% examples, 215775 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:05,810 : INFO : EPOCH 4 - PROGRESS: at 49.79% examples, 215735 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:04:06,825 : INFO : EPOCH 4 - PROGRESS: at 52.54% examples, 216410 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:07,867 : INFO : EPOCH 4 - PROGRESS: at 55.34% examples, 216940 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:08,912 : INFO : EPOCH 4 - PROGRESS: at 57.51% examples, 216906 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:09,920 : INFO : EPOCH 4 - PROGRESS: at 59.46% examples, 217354 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:10,932 : INFO : EPOCH 4 - PROGRESS: at 61.25% examples, 217255 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:11,943 : INFO : EPOCH 4 - PROGRESS: at 62.97% examples, 217145 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:13,036 : INFO : EPOCH 4 - PROGRESS: at 65.46% examples, 216993 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:14,038 : INFO : EPOCH 4 - PROGRESS: at 67.39% examples, 217238 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:15,100 : INFO : EPOCH 4 - PROGRESS: at 69.16% examples, 217087 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:16,172 : INFO : EPOCH 4 - PROGRESS: at 71.00% examples, 217210 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:17,183 : INFO : EPOCH 4 - PROGRESS: at 72.77% examples, 217354 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:04:18,217 : INFO : EPOCH 4 - PROGRESS: at 74.52% examples, 217350 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:19,237 : INFO : EPOCH 4 - PROGRESS: at 76.33% examples, 217215 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:20,304 : INFO : EPOCH 4 - PROGRESS: at 77.86% examples, 217118 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:21,320 : INFO : EPOCH 4 - PROGRESS: at 79.78% examples, 217378 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:04:22,368 : INFO : EPOCH 4 - PROGRESS: at 81.40% examples, 217112 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:23,421 : INFO : EPOCH 4 - PROGRESS: at 83.41% examples, 217364 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:24,463 : INFO : EPOCH 4 - PROGRESS: at 84.94% examples, 217355 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:04:25,465 : INFO : EPOCH 4 - PROGRESS: at 86.53% examples, 217368 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:26,481 : INFO : EPOCH 4 - PROGRESS: at 87.98% examples, 217484 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:27,506 : INFO : EPOCH 4 - PROGRESS: at 89.02% examples, 217259 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:04:28,511 : INFO : EPOCH 4 - PROGRESS: at 90.43% examples, 217524 words/s, in_qsize 8, out_qsize 0\n",
      "2024-05-02 10:04:29,543 : INFO : EPOCH 4 - PROGRESS: at 91.76% examples, 217240 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:30,548 : INFO : EPOCH 4 - PROGRESS: at 93.06% examples, 217102 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:31,606 : INFO : EPOCH 4 - PROGRESS: at 94.36% examples, 216998 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:32,624 : INFO : EPOCH 4 - PROGRESS: at 95.62% examples, 217059 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:33,640 : INFO : EPOCH 4 - PROGRESS: at 96.77% examples, 216897 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:34,651 : INFO : EPOCH 4 - PROGRESS: at 97.82% examples, 216902 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:35,704 : INFO : EPOCH 4 - PROGRESS: at 99.00% examples, 216698 words/s, in_qsize 7, out_qsize 0\n",
      "2024-05-02 10:04:36,622 : INFO : EPOCH 4: training on 16678840 raw words (12697528 effective words) took 58.6s, 216556 effective words/s\n",
      "2024-05-02 10:04:36,623 : INFO : Word2Vec lifecycle event {'msg': 'training on 83394200 raw words (63480957 effective words) took 269.4s, 235643 effective words/s', 'datetime': '2024-05-02T10:04:36.623180', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'train'}\n",
      "2024-05-02 10:04:36,624 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=336698, vector_size=100, alpha=0.025>', 'datetime': '2024-05-02T10:04:36.624181', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
      "2024-05-02 10:04:36,641 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'word2vec_cellphone_dataset.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-05-02T10:04:36.641184', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'saving'}\n",
      "2024-05-02 10:04:36,642 : INFO : storing np array 'vectors' to word2vec_cellphone_dataset.model.wv.vectors.npy\n",
      "2024-05-02 10:04:36,766 : INFO : storing np array 'syn1neg' to word2vec_cellphone_dataset.model.syn1neg.npy\n",
      "2024-05-02 10:04:36,879 : INFO : not storing attribute cum_table\n",
      "2024-05-02 10:04:37,080 : INFO : saved word2vec_cellphone_dataset.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "\n",
    "# Enable logging to monitor training\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(processedReviews, vector_size=100, window=10, min_count=1, workers=4, sg=1, epochs=5)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "print(\"Model training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab997eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:05:58,966 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 10:05:59,090 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 10:05:59,091 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 10:05:59,153 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 10:05:59,222 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 10:06:01,568 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T10:06:01.568106', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'sad': [-7.62453139e-01  1.79744571e-01 -2.77912855e-01  4.74982500e-01\n",
      " -2.39998221e-01 -5.41491091e-01  6.22987568e-01  7.12963283e-01\n",
      "  1.77537262e-01 -3.23379308e-01  9.68547761e-02 -2.88003266e-01\n",
      " -7.42764324e-02 -4.91754711e-01  1.34352148e-01 -6.97177229e-03\n",
      "  8.86024386e-02 -2.87605435e-01 -2.11195201e-01 -7.78152585e-01\n",
      " -4.22495939e-02  1.32311281e-04  4.51792061e-01 -1.05240919e-01\n",
      " -1.97358847e-01  8.78573582e-02  1.41776666e-01 -1.75810739e-01\n",
      " -1.09273359e-01 -1.16388313e-01  2.58799404e-01 -8.62805098e-02\n",
      "  8.08746696e-01 -8.83385390e-02 -3.52661073e-01  4.14920032e-01\n",
      " -3.77335958e-02  9.52805206e-02 -4.89848286e-01  2.13466175e-02\n",
      "  1.76041171e-01 -1.27792284e-01  9.54911187e-02 -5.74061334e-01\n",
      "  2.31987014e-01  1.35941803e-01  3.67190063e-01  4.45230693e-01\n",
      " -4.31805141e-02 -1.05671518e-01  5.04452288e-02  1.11367181e-01\n",
      " -1.88253298e-01  1.00054324e-01  4.74041998e-01 -4.37346622e-02\n",
      " -5.04812777e-01 -4.93020266e-02  2.71544009e-01  5.50677717e-01\n",
      " -3.73109072e-01 -3.29394713e-02  3.60866517e-01 -1.45477891e-01\n",
      " -1.34535626e-01  1.37229431e-02  2.72651762e-01  2.99844086e-01\n",
      " -4.61376935e-01  1.32622883e-01 -2.86707103e-01 -1.20976284e-01\n",
      "  2.65885770e-01  1.25999570e-01  1.70292437e-01 -4.99459743e-01\n",
      "  3.08554024e-01  1.19085222e-01  1.47886112e-01 -2.38712952e-01\n",
      " -8.00066069e-02  7.81060234e-02 -3.36094260e-01  6.05973661e-01\n",
      " -1.55549973e-01 -4.53093275e-02  4.32132959e-01  1.93515986e-01\n",
      "  2.90222406e-01  2.04591751e-01  2.95452982e-01  1.11978706e-02\n",
      " -5.94874024e-02  1.54299393e-01  1.36764005e-01 -2.20848590e-01\n",
      " -8.13446268e-02  6.76127747e-02  3.15301806e-01  3.53271097e-01]\n",
      "Similar words to 'sad': [('upset', 0.823224663734436), ('bummed', 0.8090507388114929), ('dissapointed', 0.7816551923751831), ('sad,', 0.7781417965888977), ('ecstatic', 0.7655609846115112), ('upset.', 0.7649579644203186), ('disappointed', 0.7617462873458862), ('sad.', 0.7613963484764099), ('mad', 0.7578717470169067), (';(', 0.7536247372627258)]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "word='sad'\n",
    "# Get the vector for a word\n",
    "vector = model.wv[word] \n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.wv.most_similar(word, topn=10)  \n",
    "\n",
    "print(f\"Vector for '{word}':\", vector)\n",
    "print(f\"Similar words to '{word}':\", similar_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbac925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:06:01,699 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 10:06:01,809 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 10:06:01,810 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 10:06:01,865 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 10:06:01,916 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 10:06:04,228 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T10:06:04.228662', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'smart' and 'intelligent': 0.585563\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "# Function to calculate similarity between two words\n",
    "def get_similarity(word1, word2):\n",
    "    # Check if both words are in the vocabulary\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        # Calculate similarity\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        return similarity\n",
    "    else:\n",
    "        return \"One or both words not in the vocabulary!\"\n",
    "\n",
    "# Example usage\n",
    "word1 = 'smart'  \n",
    "word2 = 'intelligent'\n",
    "\n",
    "similarity_score = get_similarity(word1, word2)\n",
    "print(f\"Similarity between '{word1}' and '{word2}':\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fb351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84770f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabba4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d200300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09162f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:06:04,263 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 10:06:04,381 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 10:06:04,382 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 10:06:04,440 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 10:06:04,507 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 10:06:06,828 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T10:06:06.828622', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'smart': [-0.62474304  0.21149507  0.06769743  0.14993449  0.01985487 -0.29991478\n",
      "  0.04586261  0.49547184  0.07829106 -0.14587606 -0.43042156 -0.3778295\n",
      "  0.01370911 -0.11172963  0.21977393  0.29459372  0.15975568  0.0533323\n",
      "  0.20558925 -0.5769275  -0.2621223   0.0994197  -0.29724824 -0.34556422\n",
      " -0.18748161 -0.12169936 -0.61801136 -0.07488485 -0.25060064  0.01139996\n",
      " -0.01886378 -0.04206012  0.65354383 -0.21056882 -0.45108247  0.24203815\n",
      "  0.14254422 -0.20052354 -0.03756392 -0.48642266  0.03443151 -0.02494771\n",
      " -0.07138032 -0.29861414  0.34869304 -0.01140315 -0.27585593 -0.17811745\n",
      " -0.05325644  0.26405892  0.04432644 -0.26436943  0.3235761  -0.06224978\n",
      " -0.32440385 -0.07821929  0.14694123 -0.18780716 -0.213641    0.1322933\n",
      "  0.08629474  0.29236683  0.20991586 -0.15338558 -0.22199905  0.10055942\n",
      "  0.14657876  0.2797962  -0.39889118  0.13266121  0.29044622  0.7231521\n",
      "  0.49417526  0.21186842  0.28964084  0.11401998  0.15221617 -0.08428616\n",
      " -0.11796649 -0.13338068 -0.47309217 -0.11916148 -0.26894072  0.8606916\n",
      " -0.03389049  0.21483436  0.31789047 -0.08796251 -0.20482033 -0.02896037\n",
      "  0.46337602  0.47361043  0.17634556 -0.18477467  0.42594576  0.14783892\n",
      " -0.2016626  -0.2244301   0.31268436 -0.5129827 ]\n",
      "Similar words to 'smart': [('cell', 0.8241211771965027), ('smartphone', 0.8032791614532471), ('non-smart', 0.8003039360046387), (\"friends'\", 0.7919125556945801), ('ereaders,', 0.7878320813179016), ('tablet!', 0.785744309425354), ('pda,', 0.783397376537323), ('phablets.', 0.7826699018478394), ('mobile', 0.7823361754417419), ('\"dumb\"', 0.7749195694923401)]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "word='smart'\n",
    "# Get the vector for a word\n",
    "vector = model.wv[word]  \n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.wv.most_similar(word, topn=10)  \n",
    "\n",
    "print(f\"Vector for '{word}':\", vector)\n",
    "print(f\"Similar words to '{word}':\", similar_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db21bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:06:06,942 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 10:06:07,036 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 10:06:07,037 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 10:06:07,081 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 10:06:07,131 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 10:06:09,520 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T10:06:09.520575', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'smart' and 'dumb': 0.6716626\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "# Function to calculate similarity between two words\n",
    "def get_similarity(word1, word2):\n",
    "    # Check if both words are in the vocabulary\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        # Calculate similarity\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        return similarity\n",
    "    else:\n",
    "        return \"One or both words not in the vocabulary!\"\n",
    "\n",
    "# Example usage\n",
    "word1 = 'smart' \n",
    "word2 = 'dumb' \n",
    "\n",
    "similarity_score = get_similarity(word1, word2)\n",
    "print(f\"Similarity between '{word1}' and '{word2}':\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fa22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479941db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac537044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7994f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305940b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:06:09,574 : INFO : loading Word2Vec object from word2vec_cellphone_dataset.model\n",
      "2024-05-02 10:06:09,709 : INFO : loading wv recursively from word2vec_cellphone_dataset.model.wv.* with mmap=None\n",
      "2024-05-02 10:06:09,710 : INFO : loading vectors from word2vec_cellphone_dataset.model.wv.vectors.npy with mmap=None\n",
      "2024-05-02 10:06:09,782 : INFO : loading syn1neg from word2vec_cellphone_dataset.model.syn1neg.npy with mmap=None\n",
      "2024-05-02 10:06:09,849 : INFO : setting ignored attribute cum_table to None\n",
      "2024-05-02 10:06:12,216 : INFO : Word2Vec lifecycle event {'fname': 'word2vec_cellphone_dataset.model', 'datetime': '2024-05-02T10:06:12.216951', 'gensim': '4.3.2', 'python': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.214\n",
      "   word1        word2  SimLex999  predicted_similarity\n",
      "0    old          new       1.58              0.641298\n",
      "1  smart  intelligent       9.20              0.585563\n",
      "2   hard    difficult       8.77              0.810085\n",
      "3  happy     cheerful       9.55              0.525473\n",
      "4   hard         easy       0.95              0.667072\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the Word2Vec model\n",
    "model = Word2Vec.load(\"word2vec_cellphone_dataset.model\")\n",
    "\n",
    "def get_similarity(model, word1, word2):\n",
    "    # Check if both words are in the vocabulary\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        # Calculate similarity\n",
    "        return model.wv.similarity(word1, word2)\n",
    "    else:\n",
    "        return None  # Return None if one or both words are not in the vocabulary\n",
    "\n",
    "# Load SimLex-999 data\n",
    "simlex_path =r\"C:\\Users\\sevan\\Desktop\\IIIT-H\\SimLex-999\\SimLex-999\\SimLex-999.txt\"  \n",
    "simlex_data = pd.read_csv(simlex_path, sep='\\t')\n",
    "\n",
    "# Calculate similarities using the model\n",
    "simlex_data['predicted_similarity'] = simlex_data.apply(lambda row: get_similarity(model, row['word1'], row['word2']), axis=1)\n",
    "\n",
    "# Drop rows where similarity could not be calculated because the word was not in the vocabulary\n",
    "simlex_data.dropna(subset=['predicted_similarity'], inplace=True)\n",
    "\n",
    "# Calculate the Spearman correlation between human ratings and model's predictions\n",
    "correlation, _ = spearmanr(simlex_data['SimLex999'], simlex_data['predicted_similarity'])\n",
    "print(f\"Spearman correlation: {correlation:.3f}\")\n",
    "\n",
    "print(simlex_data[['word1', 'word2', 'SimLex999', 'predicted_similarity']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8de8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80d215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978149c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68de989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449e4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95568cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6878db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f8d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fa707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ba158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
